# Pentest Recon Skill
> **Location**: `workspace/skills/pentest-recon/SKILL.md`

## Skill Entity

```yaml
name: pentest-recon
version: 2.0
description: |
  State-of-the-art reconnaissance methodology with decision-tree-based tool selection.
  Comprehensive framework for external penetration testing reconnaissance.
  Includes 12 tool decision matrices and 9-phase execution workflow.
author: pho5nix
agent: EagleEye
updated: 2026-02-20

triggers:
  - recon, enumeration, subdomain discovery
  - port scanning, OSINT, fingerprinting
  - URL discovery, vulnerability scanning
  - target domain/IP received for pentest
  - "start recon", "begin reconnaissance", "run enumeration"
  - "scan target", "enumerate", "discover"

dependencies:
  - subfinder, amass, dnsx, httpx, naabu, nmap
  - katana, gobuster, ffuf, nuclei, nikto
  - whatweb, wafw00f, sslscan
  - theHarvester, dnsrecon, shodan, gau, waybackurls
```

---

## Critical: Pre-Flight Checklist

### Before ANY Reconnaissance

1. **☐ Verify Scope**: Read `target/TARGETS.md` — if target not listed, **STOP** and notify operator
2. **☐ Disable Unused Features**: Web search = OFF, Research = OFF during recon
3. **☐ Check Session Budget**: Ensure sufficient time (phases 1-4: ~1hr, phases 5-7: ~2-3hr)
4. **☐ Set Environment**:

```bash
export TARGET="example.com"
export DATE=$(date +%Y-%m-%d)
export SCANDIR="$HOME/workspace/scans/$TARGET"
export REPORTDIR="$HOME/workspace/reports"
mkdir -p $SCANDIR $REPORTDIR
START=$(date +%s)
echo "Recon initialized: $TARGET @ $(date)"
```

---

## Master Decision Tree

```
                         ┌─────────────────────┐
                         │   TARGET RECEIVED   │
                         └──────────┬──────────┘
                                    │
                         ┌──────────▼──────────┐
                         │  In TARGETS.md?     │
                         └──────────┬──────────┘
                                    │
                     ┌──────────────┴─────────────┐
                     ▼                            ▼
              ┌─────────┐                    ┌─────────┐
              │   YES   │                    │   NO    │
              └────┬────┘                    └─────┬───┘
                   │                               │
                   ▼                               ▼
          ┌────────────────┐              ┌────────────────┐
          │ Phase 1: OSINT │              │ STOP & NOTIFY  │
          └───────┬────────┘              │   OPERATOR     │
                  │                       └────────────────┘
                  ▼
       ┌─────────────────────┐
       │  Is target domain?  │
       └──────────┬──────────┘
                  │
       ┌──────────┴──────────┐
       ▼                     ▼
   ┌───────┐            ┌────────┐
   │  YES  │            │   NO   │
   │Domain │            │  (IP)  │
   └───┬───┘            └───┬────┘
       │                    │
       ▼                    │
┌──────────────┐            │
│ Phase 2:     │            │
│ Subdomains   │            │
│ subfinder    │            │
│ amass        │            │
│ dnsx         │            │
└──────┬───────┘            │
       │                    │
       ▼                    │
┌──────────────┐            │
│ Phase 3:     │◄───────────┘
│ Live Hosts   │
│ httpx        │
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ Phase 4:     │
│ Port Scan    │
│ naabu → nmap │
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ Phase 5:     │
│ Fingerprint  │
│ whatweb      │
│ wafw00f      │
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ Phase 6:     │
│ URL/Path     │
│ katana       │
│ gobuster     │
│ ffuf         │
└──────┬───────┘
       │
       ▼
┌──────────────┐          
│ Phase 7:     │      ┌─────────────────────────────┐
│ Vuln Scan    │      │   CRITICAL/HIGH Finding?    │
│ nuclei       │────► │ → IMMEDIATE Telegram notify │
│ nikto        │      │ → Do NOT wait for phase end │
└──────┬───────┘      └─────────────────────────────┘
       │
       ▼
┌──────────────┐
│ Phase 8:     │
│ Report       │
└──────┬───────┘
       │
       ▼
┌──────────────┐
│ Phase 9:     │
│ Notify       │
│ Operator     │
└──────────────┘
```

---

# TOOL DECISION TREES

## 1. SUBFINDER — Subdomain Enumeration

**Purpose**: Fast passive subdomain discovery. First tool in the chain.

### Entry Decision

```
┌─────────────────────────────────────────────────────────────┐
│ IF: Target is a domain AND subdomain enumeration needed     │
│ THEN: Start with Subfinder for passive enumeration          │
└─────────────────────────────────────────────────────────────┘
```

### Mode Selection Tree

```
                    ┌──────────────────┐
                    │  Start Subfinder │
                    └────────┬─────────┘
                             │
            ┌────────────────┼────────────────┐
            ▼                ▼                ▼
     ┌────────────┐   ┌────────────┐   ┌─────────────┐
     │  Stealth   │   │   Speed    │   │Comprehensive│
     │  Priority? │   │  Priority? │   │   Needed?   │
     └─────┬──────┘   └─────┬──────┘   └──────┬──────┘
           │                │                 │
           ▼                ▼                 ▼
    subfinder -d      subfinder -d      subfinder -d
    $TARGET           $TARGET -all      $TARGET -all
    -silent           -sc 50 -hc 50     -recursive
```

### Decision Matrix

|Scenario|Command|Time|
|---|---|---|
|**Stealth required**|`subfinder -d $TARGET -silent`|2-3 min|
|**Speed priority**|`subfinder -d $TARGET -all -sc 50 -hc 50`|1-2 min|
|**Comprehensive**|`subfinder -d $TARGET -all -recursive`|5-10 min|
|**Multiple targets**|`subfinder -dL domains.txt -o results.txt`|varies|
|**API keys configured**|`subfinder -d $TARGET -all`|3-5 min|
|**Rate limited**|`subfinder -d $TARGET -sc 5 -delay 2`|10+ min|
|**Memory constrained**|Loop: `for d in $(cat domains.txt); do subfinder -d $d; done`|varies|

### Output Routing

|Next Step|Pipeline|
|---|---|
|DNS Resolution|`subfinder -d $TARGET -silent \| dnsx -a -silent`|
|HTTP Probing|`subfinder -d $TARGET -silent \| httpx -silent`|
|Port Scanning|`subfinder -d $TARGET -silent \| naabu -silent`|
|Save for later|`subfinder -d $TARGET -o $SCANDIR/$TARGET-subfinder-$DATE.txt`|

### Post-Processing Rules

- **ALWAYS** add `-nW` to remove wildcards
- **ALWAYS** dedupe with `sort -u` before next tool
- **ALWAYS** combine with Amass for completeness

---

## 2. AMASS — Advanced DNS Enumeration

**Purpose**: Comprehensive subdomain enumeration with OSINT intelligence. Slower but more thorough.

### When to Use: Amass vs Subfinder

```
┌─────────────────────────────────────────────────────────────┐
│ Quick scan needed (< 5 min)?                                │
│ → Use SUBFINDER only                                        │
├─────────────────────────────────────────────────────────────┤
│ Comprehensive enumeration needed?                           │
│ → Use BOTH Subfinder AND Amass                              │
├─────────────────────────────────────────────────────────────┤
│ Need organization intelligence (ASN, CIDR, related domains)?│
│ → Use AMASS INTEL mode                                      │
├─────────────────────────────────────────────────────────────┤
│ BEST PRACTICE: Always use both, merge results               │
└─────────────────────────────────────────────────────────────┘
```

### Mode Selection Tree

```
                    ┌─────────────────┐
                    │   Start Amass   │
                    └────────┬────────┘
                             │
         ┌───────────────────┼───────────────────┐
         ▼                   ▼                   ▼
   ┌───────────┐      ┌───────────┐      ┌───────────┐
   │   ENUM    │      │   ENUM    │      │   INTEL   │
   │  Passive  │      │  Active   │      │  Gather   │
   └─────┬─────┘      └─────┬─────┘      └─────┬─────┘
         │                  │                  │
         ▼                  ▼                  ▼
   amass enum          amass enum         amass intel
   -passive            -active            -org "Name"
   -d $TARGET          -brute             -asn 12345
                       -d $TARGET         -cidr x.x.x.x/24
```

### Decision Matrix

|Scenario|Command|Time|
|---|---|---|
|**Passive only (stealth)**|`amass enum -passive -d $TARGET`|5-10 min|
|**Active enumeration**|`amass enum -active -d $TARGET`|15-30 min|
|**With brute force**|`amass enum -brute -d $TARGET -w wordlist.txt`|30-60 min|
|**Full reconnaissance**|`amass enum -active -brute -d $TARGET`|1-2 hr|
|**Organization intel**|`amass intel -org "Company Name"`|5-15 min|
|**ASN discovery**|`amass intel -asn 12345`|2-5 min|
|**CIDR enumeration**|`amass intel -cidr 192.168.0.0/16`|varies|
|**Slow network**|`amass enum -d $TARGET -max-dns-queries 500`|slower|
|**Fast network**|`amass enum -d $TARGET -max-dns-queries 2000`|faster|

### Integration Pattern

```bash
# Standard dual-tool enumeration
subfinder -d $TARGET -all -silent > $SCANDIR/$TARGET-subfinder-$DATE.txt
amass enum -passive -d $TARGET -o $SCANDIR/$TARGET-amass-$DATE.txt

# Merge and dedupe
cat $SCANDIR/$TARGET-subfinder-$DATE.txt $SCANDIR/$TARGET-amass-$DATE.txt | sort -u > $SCANDIR/$TARGET-subs-merged-$DATE.txt

echo "Total unique subdomains: $(wc -l < $SCANDIR/$TARGET-subs-merged-$DATE.txt)"
```

---

## 3. DNSx — DNS Resolution & Validation

**Purpose**: Resolve subdomains to IPs, validate records, filter wildcards.

### Entry Decision

```
┌─────────────────────────────────────────────────────────────┐
│ IF: Have subdomain list AND need IP resolution/validation   │
│ THEN: Use DNSx                                              │
└─────────────────────────────────────────────────────────────┘
```

### Record Type Selection Tree

```
                    ┌─────────────────┐
                    │   Start DNSx    │
                    └────────┬────────┘
                             │
                   What records needed?
                             │
    ┌──────────┬─────────────┼────────────┬──────────┐
    ▼          ▼             ▼            ▼          ▼
┌───────┐ ┌────────┐    ┌───────┐    ┌───────┐  ┌───────┐
│  A    │ │ CNAME  │    │  MX   │    │  NS   │  │  ALL  │
│(IPv4) │ │Takeover│    │(Mail) │    │(Name) │  │Records│
└───┬───┘ └───┬────┘    └───┬───┘    └───┬───┘  └───┬───┘
    │         │             │            │          │
    ▼         ▼             ▼            ▼          ▼
  -a       -cname         -mx           -ns      -a -aaaa
                                                -cname -mx
```

### Decision Matrix

|Scenario|Command|
|---|---|
|**IPs only (common)**|`dnsx -l subs.txt -a -silent`|
|**IPv6 included**|`dnsx -l subs.txt -a -aaaa -silent`|
|**CNAME (takeover check)**|`dnsx -l subs.txt -cname -resp-only`|
|**Mail servers**|`dnsx -l subs.txt -mx -resp-only`|
|**Name servers**|`dnsx -l subs.txt -ns -resp-only`|
|**All records**|`dnsx -l subs.txt -a -aaaa -cname -ns -mx`|
|**Filter wildcards**|`dnsx -l subs.txt -a -wildcard`|
|**Filter by IP**|`dnsx -l subs.txt -a -resp '1.2.3.4'`|
|**Reverse lookup**|`dnsx -l ips.txt -ptr`|
|**Large list (stream)**|`dnsx -l subs.txt -a -c 200 -stream`|

### Subdomain Takeover Detection

```bash
# Find CNAMEs pointing to potentially vulnerable services
dnsx -l $SCANDIR/$TARGET-subs-merged-$DATE.txt -cname -resp-only | grep -E "(github|s3|azure|heroku|cloudfront|shopify|fastly|pantheon|readme|surge)" > $SCANDIR/$TARGET-takeover-candidates-$DATE.txt
```

### Standard Pipeline

```bash
# Resolve and save
dnsx -l $SCANDIR/$TARGET-subs-merged-$DATE.txt -a -silent -o $SCANDIR/$TARGET-resolved-$DATE.txt

echo "Resolved: $(wc -l < $SCANDIR/$TARGET-resolved-$DATE.txt)"
```

---

## 4. NAABU — Fast Port Scanning

**Purpose**: Quick port discovery optimized for recon pipelines. Use for initial discovery.

### Tool Selection: Naabu vs Nmap

```
┌─────────────────────────────────────────────────────────────┐
│ Need quick port discovery for pipeline?                     │
│ → Use NAABU (faster, better integration)                    │
├─────────────────────────────────────────────────────────────┤
│ Need detailed service enumeration?                          │
│ → Use NMAP after Naabu identifies open ports                │
├─────────────────────────────────────────────────────────────┤
│ BEST PRACTICE: Naabu (discovery) → Nmap (detail on open)    │
└─────────────────────────────────────────────────────────────┘
```

### Permission-Based Decision

```
┌─────────────────────────────────────────────────────────────┐
│ Running as root / sudo available?                           │
│ → Use SYN scan: naabu -scan-type s (faster, stealthier)     │
├─────────────────────────────────────────────────────────────┤
│ No root access?                                             │
│ → Use CONNECT scan: naabu -scan-type c (works, slower)      │
└─────────────────────────────────────────────────────────────┘
```

### Decision Matrix

|Scenario|Command|
|---|---|
|**Quick web ports**|`naabu -host $TARGET -p 80,443,8080,8443 -silent`|
|**Top 100 ports**|`naabu -host $TARGET -top-ports 100 -silent`|
|**Top 1000 ports**|`naabu -host $TARGET -top-ports 1000`|
|**All ports (slow)**|`naabu -host $TARGET -p - -rate 1000`|
|**SYN scan (root)**|`sudo naabu -host $TARGET -scan-type s`|
|**Connect scan (no root)**|`naabu -host $TARGET -scan-type c`|
|**UDP scan (root)**|`sudo naabu -host $TARGET -scan-type u -p 53,161,500`|
|**Fast network**|`naabu -host $TARGET -c 100 -rate 5000`|
|**IDS evasion**|`naabu -host $TARGET -rate 50 -scan-random-port`|
|**Skip CDN IPs**|`naabu -host $TARGET -exclude-cdn`|
|**From file**|`naabu -list hosts.txt -silent`|

### Standard Pipeline

```bash
# Quick discovery, then detailed nmap
naabu -list $SCANDIR/$TARGET-resolved-$DATE.txt -top-ports 100 -silent -o $SCANDIR/$TARGET-naabu-$DATE.txt

# Extract unique IPs for nmap
cut -d: -f1 $SCANDIR/$TARGET-naabu-$DATE.txt | sort -u > $SCANDIR/$TARGET-live-ips-$DATE.txt

echo "Hosts with open ports: $(wc -l < $SCANDIR/$TARGET-live-ips-$DATE.txt)"
```

---

## 5. NMAP — Advanced Port & Service Scanning

**Purpose**: Detailed service enumeration, version detection, OS fingerprinting, NSE scripts.

### Scan Type Selection Tree

```
                    ┌─────────────────┐
                    │   Start Nmap    │
                    └────────┬────────┘
                             │
         ┌───────────────────┼───────────────────┐
         ▼                   ▼                   ▼
   ┌───────────┐      ┌───────────┐      ┌───────────┐
   │   Quick   │      │ Standard  │      │  Stealth  │
   │   Scan    │      │   Scan    │      │   Scan    │
   └─────┬─────┘      └─────┬─────┘      └─────┬─────┘
         │                  │                  │
         ▼                  ▼                  ▼
    nmap -T4 -F       nmap -sV -sC       nmap -sS -T2
    $TARGET           $TARGET            $TARGET

```

### Decision Matrix

|Scenario|Command|
|---|---|
|**Quick TCP scan**|`nmap -T4 -F $TARGET`|
|**Full TCP scan**|`nmap -p- -T4 $TARGET`|
|**Service detection**|`nmap -sV $TARGET`|
|**OS detection**|`nmap -O $TARGET`|
|**Aggressive (full info)**|`nmap -A $TARGET`|
|**Default scripts**|`nmap -sC $TARGET`|
|**Version + scripts**|`nmap -sV -sC $TARGET`|
|**Stealth SYN**|`sudo nmap -sS -T2 $TARGET`|
|**UDP scan**|`sudo nmap -sU -p 53,67,161,500 $TARGET`|
|**Vulnerability scripts**|`nmap --script vuln $TARGET`|
|**Specific CVE**|`nmap --script http-vuln-cve2021-* $TARGET`|

### Timing Templates

|Flag|Name|Use Case|
|---|---|---|
|`-T0`|Paranoid|IDS evasion (very slow)|
|`-T1`|Sneaky|IDS evasion (slow)|
|`-T2`|Polite|Reduced load on target|
|`-T3`|Normal|Default, balanced|
|`-T4`|Aggressive|Fast, reliable networks|
|`-T5`|Insane|Very fast, may miss ports|

### Firewall Evasion

|Technique|Command|
|---|---|
|Fragment packets|`nmap -f $TARGET`|
|Decoy scan|`nmap -D RND:10 $TARGET`|
|Custom source port|`nmap --source-port 53 $TARGET`|
|Randomize hosts|`nmap --randomize-hosts $TARGET`|
|Append random data|`nmap --data-length 25 $TARGET`|
|Spoof MAC|`nmap --spoof-mac 0 $TARGET`|

### Standard Commands

```bash
# TCP scan with service detection
sudo nmap -T3 -Pn -sS -sV --min-rate 1000 -iL $SCANDIR/$TARGET-live-ips-$DATE.txt -oX $SCANDIR/$TARGET-nmap-tcp-$DATE.xml -oN $SCANDIR/$TARGET-nmap-tcp-$DATE.txt

# UDP scan (common services)
sudo nmap -T3 -Pn -sU -p 53,67,68,69,88,123,135,137,138,139,161,162,389,500,514,520,623,1900 --min-rate 500 -iL $SCANDIR/$TARGET-live-ips-$DATE.txt -oX $SCANDIR/$TARGET-nmap-udp-$DATE.xml -oN $SCANDIR/$TARGET-nmap-udp-$DATE.txt

# Count results
echo "Open TCP: $(grep -c 'open' $SCANDIR/$TARGET-nmap-tcp-$DATE.txt)"
echo "Open UDP: $(grep -c 'open' $SCANDIR/$TARGET-nmap-udp-$DATE.txt)"
```

---

## 6. HTTPX — HTTP Probing & Tech Detection

**Purpose**: Identify live HTTP services, detect technologies, capture metadata. Bridge between discovery and vuln scanning.

### Entry Decision

```
┌─────────────────────────────────────────────────────────────┐
│ IF: Have list of hosts/subdomains/IPs                       │
│ THEN: Use HTTPX to identify live web services               │
└─────────────────────────────────────────────────────────────┘
```

### Information Level Tree

```
                    ┌─────────────────┐
                    │   Start HTTPX   │
                    └────────┬────────┘
                             │
                  What information needed?
                             │
    ┌────────────┬───────────┼───────────┬──────────┐
    ▼            ▼           ▼           ▼          ▼
┌───────┐   ┌───────┐   ┌───────┐   ┌───────┐   ┌───────┐
│ Basic │   │Status │   │ Tech  │   │ Full  │   │Screen │
│ Probe │   │+Title │   │Detect │   │ Meta  │   │ shots │
└───┬───┘   └───┬───┘   └───┬───┘   └───┬───┘   └───┬───┘
    │           │           │           │           │
    ▼           ▼           ▼           ▼           ▼
 -silent    -status-code  -tech-    -status-code  -screenshot
            -title        detect    -title
                                    -tech-detect
                                    -server
```

### Decision Matrix

|Scenario|Command|
|---|---|
|**Basic probe**|`httpx -l hosts.txt -silent`|
|**With status codes**|`httpx -l hosts.txt -status-code`|
|**With titles**|`httpx -l hosts.txt -title`|
|**Tech detection**|`httpx -l hosts.txt -tech-detect`|
|**Full metadata**|`httpx -l hosts.txt -status-code -title -tech-detect -server`|
|**Screenshots**|`httpx -l hosts.txt -screenshot`|
|**Only 200 OK**|`httpx -l hosts.txt -mc 200`|
|**Exclude 404/403**|`httpx -l hosts.txt -fc 404,403`|
|**Match tech**|`httpx -l hosts.txt -tech-detect -match-tech wordpress`|
|**Custom ports**|`httpx -l hosts.txt -ports 80,443,8080,8443`|
|**Large list**|`httpx -l hosts.txt -c 100 -stream`|
|**Rate limited**|`httpx -l hosts.txt -c 10 -timeout 15 -delay 2s`|

### Standard Pipeline

```bash
# Full probe with metadata
httpx -l $SCANDIR/$TARGET-resolved-$DATE.txt -status-code -title -tech-detect -server -silent -o $SCANDIR/$TARGET-httpx-$DATE.txt

# Extract URLs for further scanning
cut -d' ' -f1 $SCANDIR/$TARGET-httpx-$DATE.txt > $SCANDIR/$TARGET-live-urls-$DATE.txt

echo "Live HTTP hosts: $(wc -l < $SCANDIR/$TARGET-live-urls-$DATE.txt)"
```

---

## 7. KATANA — Web Crawling

**Purpose**: Intelligent web crawling to discover endpoints, paths, JavaScript files, hidden functionality.

### Tool Selection: Katana vs Gobuster/FFUF

```
┌─────────────────────────────────────────────────────────────┐
│ Need to discover endpoints via crawling?                    │
│ → Use KATANA (intelligent, follows links)                   │
├─────────────────────────────────────────────────────────────┤
│ Need directory/file brute-forcing?                          │
│ → Use GOBUSTER or FFUF                                      │
├─────────────────────────────────────────────────────────────┤
│ BEST PRACTICE: Passive (wayback/gau) → Katana → Gobuster    │
└─────────────────────────────────────────────────────────────┘
```

### Crawler Mode Tree

```
                    ┌─────────────────┐
                    │  Start Katana   │
                    └────────┬────────┘
                             │
                   What crawling method?
                             │
    ┌────────────┬───────────┼───────────┬────────────┐
    ▼            ▼           ▼           ▼            ▼
┌───────┐  ┌───────┐   ┌───────┐   ┌───────┐   ┌───────┐
│ HTTP  │  │  JS   │   │Sitemap│   │Robots │   │  ALL  │
│ Crawl │  │ Parse │   │ Based │   │ Based │   │Methods│
└───┬───┘  └───┬───┘   └───┬───┘   └───┬───┘   └───┬───┘
    │          │           │           │           │
    ▼          ▼           ▼           ▼           ▼
-crawler    -js-crawl   -crawler    -crawler   -crawler
standard                sitemap     robots     standard,js,
                                               sitemap,robots
```

### Decision Matrix

|Scenario|Command|
|---|---|
|**Standard crawl**|`katana -u https://$TARGET -crawler standard`|
|**JavaScript parsing**|`katana -u https://$TARGET -js-crawl`|
|**Sitemap-based**|`katana -u https://$TARGET -crawler sitemap`|
|**All methods**|`katana -u https://$TARGET -crawler standard,js,sitemap,robots`|
|**Shallow (quick)**|`katana -u https://$TARGET -depth 1`|
|**Deep crawl**|`katana -u https://$TARGET -depth 5`|
|**Same domain only**|`katana -u https://$TARGET -crawl-scope strict`|
|**Include subdomains**|`katana -u https://$TARGET -crawl-scope subs`|
|**JavaScript files**|`katana -u https://$TARGET -extension js`|
|**Exclude images**|`katana -u https://$TARGET -exclude-extension png,jpg,gif,css`|
|**With forms**|`katana -u https://$TARGET -form-fill`|
|**Rate limited**|`katana -u https://$TARGET -concurrency 5 -delay 500`|

### Standard Pipeline

```bash
# Passive first (no target load)
echo $TARGET | waybackurls > $SCANDIR/$TARGET-wayback-$DATE.txt
echo $TARGET | gau --ft "\.jpg$|\.png$|\.gif$|\.css$" > $SCANDIR/$TARGET-gau-$DATE.txt

# Active crawling
katana -u https://$TARGET -silent -depth 3 -exclude-extension png,jpg,gif,css,woff,woff2,ttf -o $SCANDIR/$TARGET-katana-$DATE.txt

# Combine passive + active
cat $SCANDIR/$TARGET-wayback-$DATE.txt $SCANDIR/$TARGET-gau-$DATE.txt $SCANDIR/$TARGET-katana-$DATE.txt | sort -u > $SCANDIR/$TARGET-urls-all-$DATE.txt

echo "URLs discovered: $(wc -l < $SCANDIR/$TARGET-urls-all-$DATE.txt)"
```

---

## 8. GOBUSTER — Directory Brute-forcing

**Purpose**: Discover hidden directories, files, and paths via wordlist brute-forcing.

### Mode Selection Tree

```
                    ┌─────────────────┐
                    │ Start Gobuster  │
                    └────────┬────────┘
                             │
                   What to brute-force?
                             │
    ┌────────────┬───────────┼───────────┬─────────┐
    ▼            ▼           ▼           ▼         ▼
┌───────┐  ┌───────┐   ┌───────┐   ┌───────┐   ┌───────┐
│  DIR  │  │  DNS  │   │ VHOST │   │  S3   │   │ FUZZ  │
│ Mode  │  │ Mode  │   │ Mode  │   │Buckets│   │ Mode  │
└───┬───┘  └───┬───┘   └───┬───┘   └───┬───┘   └───┬───┘
    │          │           │           │           │
    ▼          ▼           ▼           ▼           ▼
gobuster    gobuster    gobuster    gobuster   gobuster
dir         dns         vhost       s3         fuzz
```

### Decision Matrix

|Scenario|Command|
|---|---|
|**Directory enumeration**|`gobuster dir -u https://$TARGET -w wordlist.txt`|
|**DNS subdomain**|`gobuster dns -d $TARGET -w wordlist.txt`|
|**Virtual host**|`gobuster vhost -u https://$TARGET -w wordlist.txt`|
|**S3 buckets**|`gobuster s3 -w bucket-names.txt`|
|**PHP app**|`gobuster dir -u $URL -w list.txt -x php,php5,phtml`|
|**ASP.NET**|`gobuster dir -u $URL -w list.txt -x asp,aspx,ashx`|
|**Java**|`gobuster dir -u $URL -w list.txt -x jsp,jsf,do,action`|
|**Backup files**|`gobuster dir -u $URL -w list.txt -x bak,old,backup,~,swp`|
|**Config files**|`gobuster dir -u $URL -w list.txt -x xml,conf,config,ini,env`|
|**Hide 404**|`gobuster dir -u $URL -w list.txt -b 404`|
|**Hide 403+404**|`gobuster dir -u $URL -w list.txt -b 404,403`|
|**Faster**|`gobuster dir -u $URL -w list.txt -t 50`|
|**Rate limited**|`gobuster dir -u $URL -w list.txt -t 5 --delay 100ms`|

### Wordlist Strategy (CRITICAL)

|Wordlist|Size|Time|Use Case|
|---|---|---|---|
|`common.txt`|~5K|2-3 min|Quick baseline, always run|
|`directory-list-2.3-medium.txt`|~220K|15-20 min|Comprehensive, recommended|
|`directory-list-2.3-big.txt`|~500K+|1+ hr|**AVOID** - diminishing returns|
|`web-extensions.txt`|~100|<1 min|Add file extensions|
|`api-endpoints.txt`|~1K|2-3 min|API discovery|

**Decision Rule**:

```
ALWAYS run: common.txt (quick baseline)
USUALLY run: directory-list-2.3-medium.txt (good coverage)
RARELY run: big.txt (only if medium found interesting patterns)
TIME BUDGET: ~25-30 min total for directory enumeration
```

### Standard Pipeline

```bash
# Quick baseline
gobuster dir -u https://$TARGET -w /usr/share/seclists/Discovery/Web-Content/common.txt -o $SCANDIR/$TARGET-gobuster-common-$DATE.txt -q --no-error

# Comprehensive (if time permits)
gobuster dir -u https://$TARGET -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -o $SCANDIR/$TARGET-gobuster-medium-$DATE.txt -q --no-error

# Merge results
cat $SCANDIR/$TARGET-gobuster-*.txt | sort -u > $SCANDIR/$TARGET-dirs-merged-$DATE.txt

echo "Directories found: $(wc -l < $SCANDIR/$TARGET-dirs-merged-$DATE.txt)"
```

---

## 9. FFUF — Flexible Fuzzing

**Purpose**: Advanced fuzzing for directories, parameters, headers, and more. More flexible than Gobuster.

### When to Use: FFUF vs Gobuster

```
┌─────────────────────────────────────────────────────────────┐
│ Simple directory brute-forcing?                             │
│ → Use GOBUSTER (simpler, faster for basic tasks)            │
├─────────────────────────────────────────────────────────────┤
│ Need parameter fuzzing, header fuzzing, or complex patterns?│
│ → Use FFUF (more flexible and powerful)                     │
├─────────────────────────────────────────────────────────────┤
│ Need to fuzz POST data or JSON bodies?                      │
│ → Use FFUF                                                  │
└─────────────────────────────────────────────────────────────┘
```

### Fuzzing Mode Tree

```
                    ┌─────────────────┐
                    │   Start FFUF    │
                    └────────┬────────┘
                             │
                       What to fuzz?
                             │
    ┌───────────┬────────────┼────────────┬──────────┐
    ▼           ▼            ▼            ▼          ▼
┌───────┐   ┌───────┐    ┌───────┐    ┌───────┐  ┌───────┐
│  DIR  │   │ PARAM │    │ VALUE │    │HEADER │  │ POST  │
│ Path  │   │ Name  │    │Fuzzing│    │Fuzzing│  │ Data  │
└───┬───┘   └───┬───┘    └───┬───┘    └───┬───┘  └───┬───┘
    │           │            │            │          │
    ▼           ▼            ▼            ▼          ▼
/FUZZ       ?FUZZ=x      ?id=FUZZ    -H "X:FUZZ"  -d "x=FUZZ"
```

### Decision Matrix

|Scenario|Command|
|---|---|
|**Directory fuzzing**|`ffuf -u https://$TARGET/FUZZ -w wordlist.txt`|
|**Parameter name**|`ffuf -u https://$TARGET?FUZZ=test -w params.txt`|
|**Parameter value**|`ffuf -u https://$TARGET?id=FUZZ -w values.txt`|
|**Header fuzzing**|`ffuf -u https://$TARGET -H 'X-Custom: FUZZ' -w wordlist.txt`|
|**POST data**|`ffuf -u $URL -X POST -d 'user=FUZZ' -w wordlist.txt`|
|**JSON body**|`ffuf -u $URL -X POST -H 'Content-Type: application/json' -d '{"id":"FUZZ"}' -w values.txt`|
|**Multi-position**|`ffuf -u https://$TARGET/FUZZ1/FUZZ2 -w w1:FUZZ1 -w w2:FUZZ2`|
|**Match status**|`ffuf -u $URL/FUZZ -w list.txt -mc 200,301,302`|
|**Filter status**|`ffuf -u $URL/FUZZ -w list.txt -fc 404,403`|
|**Filter size**|`ffuf -u $URL/FUZZ -w list.txt -fs 0`|
|**Filter words**|`ffuf -u $URL/FUZZ -w list.txt -fw 10`|
|**Rate limited**|`ffuf -u $URL/FUZZ -w list.txt -t 10 -rate 50`|
|**Silent mode**|`ffuf -u $URL/FUZZ -w list.txt -s`|

### Standard Pipeline

```bash
# API endpoint discovery
ffuf -u https://$TARGET/FUZZ -w /usr/share/seclists/Discovery/Web-Content/api/api-endpoints.txt -mc 200,201,301,302,401,403 -o $SCANDIR/$TARGET-ffuf-api-$DATE.json -of json -s

# Parameter fuzzing (common params)
ffuf -u "https://$TARGET?FUZZ=test" -w /usr/share/seclists/Discovery/Web-Content/burp-parameter-names.txt -mc 200 -fs 0 -o $SCANDIR/$TARGET-ffuf-params-$DATE.json -of json -s
```

---

## 10. WHATWEB — Technology Fingerprinting

**Purpose**: Identify web technologies, CMS, frameworks, servers.

### Aggression Level Tree

```
                     ┌─────────────────┐
                     │  Start WhatWeb  │
                     └────────┬────────┘
                              │
                    Stealth requirement?
                              │
    ┌────────────┬────────────┼─────────────┬───────────┐
    ▼            ▼            ▼             ▼           ▼
┌─────────┐  ┌────────┐  ┌──────────┐   ┌───────┐   ┌───────┐
│ Stealthy│  │Standard│  │Aggressive│   │ Heavy │   │Passive│
│ Level 1 │  │Level 2 │  │ Level 3  │   │Level 4│   │ Only  │
└───┬─────┘  └───┬────┘  └────┬─────┘   └───┬───┘   └───┬───┘
    │            │            │             │           │
    ▼            ▼            ▼             ▼           ▼
  -a 1         -a 2         -a 3          -a 4        httpx
 (passive)    (default)    (active)      (noisy)    -tech-detect
```

### Decision Matrix

|Scenario|Command|
|---|---|
|**Passive (stealth)**|`whatweb -a 1 https://$TARGET`|
|**Standard**|`whatweb -a 2 https://$TARGET` (default)|
|**Aggressive**|`whatweb -a 3 https://$TARGET`|
|**Heavy (noisy)**|`whatweb -a 4 https://$TARGET`|
|**From file**|`whatweb -i urls.txt`|
|**Brief output**|`whatweb --log-brief brief.txt https://$TARGET`|
|**JSON output**|`whatweb --log-json results.json https://$TARGET`|
|**Verbose**|`whatweb -v https://$TARGET`|

### Standard Pipeline

```bash
# Fingerprint all live hosts
whatweb -i $SCANDIR/$TARGET-live-urls-$DATE.txt --log-brief $SCANDIR/$TARGET-whatweb-$DATE.txt

# WAF detection
wafw00f -i $SCANDIR/$TARGET-live-urls-$DATE.txt -o $SCANDIR/$TARGET-wafw00f-$DATE.txt

# SSL/TLS analysis (if HTTPS)
grep "https://" $SCANDIR/$TARGET-live-urls-$DATE.txt | while read url; do
  sslscan --no-failed "$url" >> $SCANDIR/$TARGET-sslscan-$DATE.txt 2>/dev/null
done
```

---

## 11. NUCLEI — Vulnerability Scanning

**Purpose**: Template-based vulnerability detection. Primary tool for identifying security issues.

### Entry Decision

```
┌─────────────────────────────────────────────────────────────┐
│ IF: Have list of live HTTP endpoints                        │
│ THEN: Use Nuclei for vulnerability detection                │
├─────────────────────────────────────────────────────────────┤
│ First time scanning target?                                 │
│ → Start with discovery templates, then escalate             │
└─────────────────────────────────────────────────────────────┘
```

### Template Selection Tree

```
                    ┌─────────────────┐
                    │  Start Nuclei   │
                    └────────┬────────┘
                             │
                     What type of scan?
                             │
    ┌────────────┬───────────┼───────────┬────────────┐
    ▼            ▼           ▼           ▼            ▼
┌───────┐  ┌───────┐   ┌─────────┐   ┌────────┐   ┌───────┐
│ Quick │  │  CVE  │   │Misconfig│   │ Tech   │   │  Full │
│ Disco │  │ Scan  │   │  Scan   │   │Specific│   │  Scan │
└───┬───┘  └───┬───┘   └────┬────┘   └───┬────┘   └───┬───┘
    │          │            │            │            │
    ▼          ▼            ▼            ▼            ▼
-tags       -tags         -tags       -t tech/     -tags cve,
tech,       cve           misconfig   wordpress/   misconfig,
exposure                               jira/        exposure
``` 

### Decision Matrix

|Scenario|Command|
|---|---|
|**Quick discovery**|`nuclei -l urls.txt -tags tech,exposure`|
|**CVE scanning**|`nuclei -l urls.txt -tags cve`|
|**Misconfigurations**|`nuclei -l urls.txt -tags misconfig`|
|**Full security scan**|`nuclei -l urls.txt -tags cve,misconfig,exposure`|
|**Tech-specific**|`nuclei -l urls.txt -t wordpress/`|
|**Critical only**|`nuclei -l urls.txt -severity critical`|
|**High + Critical**|`nuclei -l urls.txt -severity high,critical`|
|**Exclude info/low**|`nuclei -l urls.txt -exclude-severity info,low`|
|**Aggressive**|`nuclei -l urls.txt -c 50 -rate-limit 300`|
|**Careful (WAF)**|`nuclei -l urls.txt -c 10 -rate-limit 30`|
|**OOB testing**|`nuclei -l urls.txt -interactsh-server https://oast.me`|
|**Headless**|`nuclei -l urls.txt -headless`|
|**JSON output**|`nuclei -l urls.txt -j -o results.json`|

### Standard Pipeline

```bash
# Discovery + CVE + Misconfig (medium+ severity)
nuclei -l $SCANDIR/$TARGET-live-urls-$DATE.txt -t ~/nuclei-templates/ -tags discovery,cve,misconfig,exposure -severity medium,high,critical -silent -o $SCANDIR/$TARGET-nuclei-$DATE.txt

# Count by severity
echo "Critical: $(grep -c '\[critical\]' $SCANDIR/$TARGET-nuclei-$DATE.txt)"
echo "High:     $(grep -c '\[high\]' $SCANDIR/$TARGET-nuclei-$DATE.txt)"
echo "Medium:   $(grep -c '\[medium\]' $SCANDIR/$TARGET-nuclei-$DATE.txt)"
```

### CRITICAL Finding Protocol

**IMMEDIATE notification for CRITICAL/HIGH findings:**

```
CRITICAL | [CVE-XXXX-XXXX] | Host: [host] | [brief description]
Awaiting operator action before proceeding.
```

---

## 12. NIKTO — Web Server Scanning

**Purpose**: Comprehensive web server scanner for dangerous files, outdated servers, misconfigurations.

### Entry Decision

```
┌─────────────────────────────────────────────────────────────┐
│ Need comprehensive web server security check?               │
│ → Use NIKTO (thorough but slow and noisy)                   │
├─────────────────────────────────────────────────────────────┤
│ Stealth required?                                           │
│ → AVOID Nikto (very noisy, easily detected)                 │
└─────────────────────────────────────────────────────────────┘
```

### Tuning Reference

|Tuning|Description|Risk|
|---|---|---|
|1|Interesting files (logs, backups)|Low|
|2|Misconfiguration (default files)|Low|
|3|Information disclosure|Low|
|4|XSS/Script injection points|Medium|
|5|Remote file retrieval (includes)|Medium|
|6|DoS tests|**AVOID**|
|7|Remote shell / Command exec|Medium|
|8|SQL injection|Medium|
|9|File upload vulnerabilities|Medium|
|b|Software identification|Low|
|c|Remote source inclusion|Medium|
|d|WebService vulnerabilities|Medium|

### Decision Matrix

|Scenario|Command|
|---|---|
|**Full scan (recommended)**|`nikto -h https://$TARGET -Tuning 123457890bcd`|
|**Quick scan**|`nikto -h https://$TARGET -Tuning 123`|
|**Info disclosure only**|`nikto -h https://$TARGET -Tuning 3`|
|**SSL checks**|`nikto -h https://$TARGET -Tuning 7`|
|**HTML report**|`nikto -h https://$TARGET -o report.html -Format html`|
|**With proxy**|`nikto -h https://$TARGET -useproxy http://127.0.0.1:8080`|
|**Time limited**|`nikto -h https://$TARGET -maxtime 300`|
|**Rate limited**|`nikto -h https://$TARGET -Pause 2`|

### Standard Pipeline

```bash
# Full scan with HTML report (avoid DoS tuning 6)
nikto -h $SCANDIR/$TARGET-live-urls-$DATE.txt -Tuning 123457890bcd -o $SCANDIR/$TARGET-nikto-$DATE.html -Format html

echo "Nikto scan complete: $SCANDIR/$TARGET-nikto-$DATE.html"
```

---

# PHASE EXECUTION

## Phase 1 — Passive OSINT

**Goal**: Gather intelligence without touching the target. **Time**: 10-15 min

```bash
# Whois & DNS
whois $TARGET > $SCANDIR/$TARGET-whois-$DATE.txt
dig $TARGET ANY > $SCANDIR/$TARGET-dig-$DATE.txt
dnsrecon -d $TARGET -t std > $SCANDIR/$TARGET-dnsrecon-$DATE.txt

# OSINT sources
theHarvester -d $TARGET -l 500 -b all > $SCANDIR/$TARGET-harvester-$DATE.txt
shodan search hostname:$TARGET > $SCANDIR/$TARGET-shodan-$DATE.txt 2>/dev/null

# Summary
EMAILS=$(grep -c "@" $SCANDIR/$TARGET-harvester-$DATE.txt 2>/dev/null || echo 0)
echo "Phase 1 complete: $EMAILS emails found"
```

**Telegram**: `Phase 1 OSINT | Emails: N | IPs: N | Notable: [finding] | → Phase 2`

---

## Phase 2 — Subdomain Enumeration

**Goal**: Build comprehensive subdomain list. **Time**: 15-30 min

```bash
# Passive enumeration (both tools)
subfinder -d $TARGET -all -silent > $SCANDIR/$TARGET-subfinder-$DATE.txt
amass enum -passive -d $TARGET -o $SCANDIR/$TARGET-amass-$DATE.txt

# Merge and dedupe
cat $SCANDIR/$TARGET-subfinder-$DATE.txt \
    $SCANDIR/$TARGET-amass-$DATE.txt | sort -u > $SCANDIR/$TARGET-subs-merged-$DATE.txt

# Resolve
dnsx -l $SCANDIR/$TARGET-subs-merged-$DATE.txt -a -silent -o $SCANDIR/$TARGET-resolved-$DATE.txt

FOUND=$(wc -l < $SCANDIR/$TARGET-subs-merged-$DATE.txt)
RESOLVED=$(wc -l < $SCANDIR/$TARGET-resolved-$DATE.txt)
echo "Phase 2 complete: $FOUND found, $RESOLVED resolved"
```

**Telegram**: `Phase 2 Subs | Found: N | Resolved: N | Notable: [interesting] | → Phase 3`

---

## Phase 3 — Live Host Discovery

**Goal**: Identify live HTTP/HTTPS services. **Time**: 5-15 min

```bash
# HTTP probe with metadata
httpx -l $SCANDIR/$TARGET-resolved-$DATE.txt -status-code -title -tech-detect -server -silent -o $SCANDIR/$TARGET-httpx-$DATE.txt

# Extract URLs
cut -d' ' -f1 $SCANDIR/$TARGET-httpx-$DATE.txt > $SCANDIR/$TARGET-live-urls-$DATE.txt

LIVE=$(wc -l < $SCANDIR/$TARGET-live-urls-$DATE.txt)
echo "Phase 3 complete: $LIVE live hosts"
```

**Telegram**: `Phase 3 Live | HTTP: N alive | Notable: [403s, admin] | → Phase 4`

---

## Phase 4 — Port Scanning

**Goal**: Comprehensive service discovery. **Time**: 20-45 min

```bash
# Extract IPs
grep -oP '\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}' $SCANDIR/$TARGET-httpx-$DATE.txt | sort -u > $SCANDIR/$TARGET-live-ips-$DATE.txt

# TCP scan
sudo nmap -T3 -Pn -sS -sV --min-rate 1000 -iL $SCANDIR/$TARGET-live-ips-$DATE.txt -oX $SCANDIR/$TARGET-nmap-tcp-$DATE.xml -oN $SCANDIR/$TARGET-nmap-tcp-$DATE.txt

# UDP scan (common)
sudo nmap -T3 -Pn -sU -p 53,67,123,161,500,514,1900 --min-rate 500 -iL $SCANDIR/$TARGET-live-ips-$DATE.txt -oN $SCANDIR/$TARGET-nmap-udp-$DATE.txt

TCP=$(grep -c 'open' $SCANDIR/$TARGET-nmap-tcp-$DATE.txt 2>/dev/null || echo 0)
echo "Phase 4 complete: $TCP open TCP ports"
```

**Telegram**: `Phase 4 Ports | TCP: N open | Services: [list] | → Phase 5`

---

## Phase 5 — Fingerprinting

**Goal**: Identify technologies, CMS, WAF, SSL issues. **Time**: 10-20 min

```bash
# Technology fingerprinting
whatweb -i $SCANDIR/$TARGET-live-urls-$DATE.txt --log-brief $SCANDIR/$TARGET-whatweb-$DATE.txt

# WAF detection
wafw00f -i $SCANDIR/$TARGET-live-urls-$DATE.txt -o $SCANDIR/$TARGET-wafw00f-$DATE.txt 2>/dev/null

# SSL analysis
grep "https://" $SCANDIR/$TARGET-live-urls-$DATE.txt | head -10 | while read url; do
  sslscan --no-failed "$url" >> $SCANDIR/$TARGET-sslscan-$DATE.txt 2>/dev/null
done

echo "Phase 5 complete: Fingerprinting done"
```

**Telegram**: `Phase 5 FP | CMS: [list] | WAF: [yes/no] | SSL issues: N | → Phase 6`

---

## Phase 6 — URL & Path Discovery

**Goal**: Map endpoints, APIs, hidden paths. **Time**: 30-45 min

```bash
# Passive (no target load)
echo $TARGET | waybackurls > $SCANDIR/$TARGET-wayback-$DATE.txt 2>/dev/null
echo $TARGET | gau --ft "\.jpg$|\.png$|\.gif$|\.css$" > $SCANDIR/$TARGET-gau-$DATE.txt 2>/dev/null

# Active crawling
katana -u https://$TARGET -silent -depth 3 -exclude-extension png,jpg,gif,css,woff,woff2 -o $SCANDIR/$TARGET-katana-$DATE.txt

# Directory brute-force (balanced wordlists)
gobuster dir -u https://$TARGET -w /usr/share/seclists/Discovery/Web-Content/common.txt -o $SCANDIR/$TARGET-gobuster-common-$DATE.txt -q --no-error

gobuster dir -u https://$TARGET -w /usr/share/seclists/Discovery/Web-Content/directory-list-2.3-medium.txt -o $SCANDIR/$TARGET-gobuster-medium-$DATE.txt -q --no-error

# API discovery
ffuf -u https://$TARGET/FUZZ -w /usr/share/seclists/Discovery/Web-Content/api/api-endpoints.txt -mc 200,201,301,302,401,403 -o $SCANDIR/$TARGET-ffuf-api-$DATE.json -of json -s

# Merge all
cat $SCANDIR/$TARGET-wayback-$DATE.txt $SCANDIR/$TARGET-gau-$DATE.txt $SCANDIR/$TARGET-katana-$DATE.txt $SCANDIR/$TARGET-gobuster-*.txt 2>/dev/null | sort -u > $SCANDIR/$TARGET-paths-all-$DATE.txt

PATHS=$(wc -l < $SCANDIR/$TARGET-paths-all-$DATE.txt)
echo "Phase 6 complete: $PATHS paths discovered"
```

**Telegram**: `Phase 6 URLs | Wayback: N | Dirs: N | Notable: [/admin, /api] | → Phase 7`

---

## Phase 7 — Vulnerability Scanning

**Goal**: Identify CVEs and misconfigurations. **NO EXPLOITATION.** **Time**: 30-60 min

```bash
# Nuclei scan (medium+ severity)
nuclei -l $SCANDIR/$TARGET-live-urls-$DATE.txt -t ~/nuclei-templates/ -tags discovery,cve,misconfig,exposure -severity medium,high,critical -silent -o $SCANDIR/$TARGET-nuclei-$DATE.txt

# Nikto scan (skip DoS)
nikto -h https://$TARGET -Tuning 123457890bcd -o $SCANDIR/$TARGET-nikto-$DATE.html -Format html

# Count findings
CRIT=$(grep -c '\[critical\]' $SCANDIR/$TARGET-nuclei-$DATE.txt 2>/dev/null || echo 0)
HIGH=$(grep -c '\[high\]' $SCANDIR/$TARGET-nuclei-$DATE.txt 2>/dev/null || echo 0)
MED=$(grep -c '\[medium\]' $SCANDIR/$TARGET-nuclei-$DATE.txt 2>/dev/null || echo 0)

echo "Phase 7 complete: $CRIT critical, $HIGH high, $MED medium"

# CRITICAL ALERT (if any)
if [ "$CRIT" -gt 0 ] || [ "$HIGH" -gt 0 ]; then
  echo "CRITICAL/HIGH findings detected - notify operator immediately!"
fi
```

**Telegram**: `Phase 7 Vulns | Critical: N | High: N | Medium: N | → Phase 8`

**CRITICAL FINDING**: Notify immediately, don't wait!

---

## Phase 8 — Report Generation

# Create HTML report with styling (see example below)
# Then convert to PDF:

wkhtmltopdf \
  --quiet \
  --margin-top 0.75in \
  --margin-bottom 0.75in \
  --margin-left 0.75in \
  --margin-right 0.75in \
  --header-center "Penetration Test Report - $TARGET" \
  --header-font-size 9 \
  --header-spacing 5 \
  --footer-right "[page]/[topage]" \
  --footer-font-size 8 \
  --footer-spacing 5 \
  --enable-local-file-access \
  "$HTML_FILE" "$REPORTDIR/$TARGET-summary-$DATE.pdf"

if [ -f "$REPORTDIR/$TARGET-summary-$DATE.pdf" ]; then
  echo "✓ PDF Report generated: $REPORTDIR/$TARGET-summary-$DATE.pdf"
  ls -lh "$REPORTDIR/$TARGET-summary-$DATE.pdf"
else
  echo "✗ PDF generation failed"
  exit 1
fi
```

**HTML Report Template** (minimal example):

```html
<!DOCTYPE html>
<html>
<head>
<title>Penetration Test Report - $TARGET</title>
<style>
  body { font-family: Arial, sans-serif; line-height: 1.6; color: #333; margin: 20px; }
  h1 { color: #1a1a1a; border-bottom: 3px solid #4472C4; padding-bottom: 10px; }
  h2 { color: #4472C4; margin-top: 30px; }
  table { width: 100%; border-collapse: collapse; margin: 15px 0; }
  th { background-color: #4472C4; color: white; padding: 12px; text-align: left; }
  td { border: 1px solid #ddd; padding: 10px; }
  tr:nth-child(even) { background-color: #f2f2f2; }
  .high-risk { background-color: #ffe6e6; border-left: 4px solid #d32f2f; padding: 15px; margin: 15px 0; }
  pre { background-color: #f5f5f5; border: 1px solid #ddd; padding: 12px; overflow-x: auto; }
</style>
</head>
<body>
<h1>Penetration Test Report</h1>
<p><strong>Target:</strong> $TARGET | <strong>Date:</strong> $DATE | <strong>Operator:</strong> $OPERATOR</p>
<h2>Executive Summary</h2>
<p>Summary of findings...</p>
<h2>Critical Findings</h2>
<div class="high-risk"><strong>Finding 1:</strong> Description...</div>
<h2>Reconnaissance Results</h2>
<table>
  <tr><th>Phase</th><th>Tool</th><th>Results</th></tr>
  <tr><td>1. OSINT</td><td>theHarvester</td><td>N findings</td></tr>
</table>
</body>
</html>
```

Save to: `$REPORTDIR/$TARGET-summary-$DATE.pdf`

---

## Phase 9 — Operator Notification

**Goal**: Final summary to operator.

```bash
ELAPSED=$(( ($(date +%s) - START) / 60 ))

echo "
═══════════════════════════════════════════════════════
EagleEye — Recon Complete
═══════════════════════════════════════════════════════
Target: $TARGET
Date: $DATE
Duration: ${ELAPSED} minutes

Results:
• Subdomains: $(wc -l < $SCANDIR/$TARGET-resolved-$DATE.txt 2>/dev/null || echo 0) resolved
• Live hosts: $(wc -l < $SCANDIR/$TARGET-live-urls-$DATE.txt 2>/dev/null || echo 0) online
• Open ports: $(grep -c 'open' $SCANDIR/$TARGET-nmap-tcp-$DATE.txt 2>/dev/null || echo 0) TCP
• Critical: $(grep -c '\[critical\]' $SCANDIR/$TARGET-nuclei-$DATE.txt 2>/dev/null || echo 0)
• High: $(grep -c '\[high\]' $SCANDIR/$TARGET-nuclei-$DATE.txt 2>/dev/null || echo 0)
• Medium: $(grep -c '\[medium\]' $SCANDIR/$TARGET-nuclei-$DATE.txt 2>/dev/null || echo 0)

Report: $REPORTDIR/$TARGET-summary-$DATE.pdf
═══════════════════════════════════════════════════════
"
```

---

# QUICK REFERENCE

## Tool Selection Matrix

|Phase|Primary|Alternative|When to Use Alternative|
|---|---|---|---|
|Subdomain Enum|Subfinder|Amass|Need comprehensive/intel|
|DNS Resolution|DNSx|dig/host|Single queries|
|Port Discovery|Naabu|Nmap|Need service detection|
|Service Detection|Nmap -sV|Naabu -sv|Quick check only|
|HTTP Probing|HTTPX|curl|Single URL testing|
|Tech Detection|HTTPX/WhatWeb|-|Use both|
|Web Crawling|Katana|hakrawler|Simpler needs|
|Dir Brute-force|Gobuster|FFUF|Need param fuzzing|
|Vuln Scanning|Nuclei|Nikto|Web server focus|

## Time Budget Guide

|Budget|Approach|Phases|
|---|---|---|
|< 30 min|`subfinder \| httpx \| nuclei -tags tech`|2,3,7 only|
|< 2 hours|Passive + httpx + naabu + nuclei|1-4, 7|
|5+ hours|Complete 9-phase methodology|All phases|

## Stealth Levels

|Level|Tools|Noise|
|---|---|---|
|Maximum stealth|subfinder, amass -passive, waybackurls|None|
|Low noise|httpx, katana -depth 1|Minimal|
|Normal|naabu, gobuster -t 10|Moderate|
|Aggressive|nmap -A, nikto, gobuster -t 50|High|
